# ============================================================================
# Code Review Benchmark - Environment Configuration
# ============================================================================
# Copy this file to .env and configure as needed

# ----------------------------------------------------------------------------
# Required: API Keys
# ----------------------------------------------------------------------------

# OpenAI API key for LLM-as-judge evaluation and most review tools
OPENAI_API_KEY=sk-...

# ----------------------------------------------------------------------------
# Optional: Model Configuration
# ----------------------------------------------------------------------------

# Model used for LLM-as-judge evaluation (default: gpt-4o)
# Options: gpt-4o, gpt-4-turbo, gpt-3.5-turbo
# CRB_JUDGE_MODEL=gpt-4o

# Model passed to review tools that support model selection
# CRB_TOOL_MODEL=gpt-4o

# ----------------------------------------------------------------------------
# Optional: Benchmark Configuration
# ----------------------------------------------------------------------------

# Number of runs per tool/challenge pair (default: 3)
# More runs = better statistical significance but higher cost
# CRB_NUM_RUNS=3

# Timeout for each tool run in seconds (default: 300)
# CRB_TOOL_TIMEOUT=300

# Enable debug output (default: false)
# CRB_DEBUG=false

# Results directory (default: ./results)
# CRB_RESULTS_DIR=./results

# ----------------------------------------------------------------------------
# Optional: Tool-Specific Configuration
# ----------------------------------------------------------------------------

# PR-Agent specific settings
# PR_AGENT_MODEL=gpt-4o
# PR_AGENT_TIMEOUT=120

# Shippie specific settings
# SHIPPIE_API_KEY=...

# XAI Review specific settings
# XAI_REVIEW_MODEL=gpt-4o

# OpenAI Reviewer settings (uses OPENAI_API_KEY from above)
# CRB_OPENAI_MODEL=gpt-4o

# Claude Reviewer settings
# ANTHROPIC_API_KEY=sk-ant-...
# CRB_CLAUDE_MODEL=claude-opus-4-20250514
# CRB_CLAUDE_USE_BEDROCK=false
# AWS_PROFILE=your-profile  # Only needed with CRB_CLAUDE_USE_BEDROCK=true
# AWS_REGION=us-east-1       # Only needed with CRB_CLAUDE_USE_BEDROCK=true

# ----------------------------------------------------------------------------
# Optional: Evaluation Settings
# ----------------------------------------------------------------------------

# Skip LLM evaluation and use only heuristic matching (default: false)
# Useful for development/testing to save API costs
# CRB_SKIP_LLM_EVAL=false

# Heuristic matching thresholds (0.0 to 1.0)
# CRB_HEURISTIC_THRESHOLD=0.7

# LLM confidence threshold for matching (0.0 to 1.0)
# CRB_LLM_CONFIDENCE_THRESHOLD=0.8

# ----------------------------------------------------------------------------
# Optional: Development Settings
# ----------------------------------------------------------------------------

# Enable local development mode (uses mock data)
# CRB_DEV_MODE=false

# Cache LLM responses for development (saves API costs)
# CRB_CACHE_LLM_RESPONSES=false

# Verbose logging
# CRB_VERBOSE=false
